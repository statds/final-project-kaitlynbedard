---
title: "NYC Arrests"
subtitle: "Statistical Analysis"
author: "Kaitlyn Bedard"
format:
  revealjs:
   # theme: moon
    transition: slide 
    embed-resources: true
    slide-number: true
 #   chalkboard: 
  #    buttons: false
    preview-links: auto
   # logo: images/quarto.png
  #  css: styles.css
    footer: "UConn Intro to Data Science: STAT 3255/5255"
    code-fold: true
execute:
  warning: false
  error: false
resources:
  - demo.pdf
---


## Outline 
- Background Information
- Data Description and Cleaning
- Exploratory Analysis and Graphing
- Hypothesis Testing
- Modeling Arrests 
- Conclusions

## Background Information
** fill in **



## Data Description and Cleaning
```{python}
#| echo: false

# load data
import geopandas as gpd

arrests = gpd.read_file("data/nycarrest_09012022-10012022.geojson")
arrests.set_crs("EPSG:4326")

arrests.head()
```

```{python}
#| echo: false

cleaned = arrests.copy()

# removing columns that won't be used (redundant and unneccessary)
cleaned = arrests.drop(columns=['@computed_region_92fq_4b7q', '@computed_region_efsh_h5xi', '@computed_region_sbqj_enih',
                                 '@computed_region_yeji_bk3q', '@computed_region_f5dn_yrer', 'arrest_key', 'x_coord_cd', 'y_coord_cd',
                                 'jurisdiction_code', 'ky_cd', 'pd_cd', 'pd_desc', 'arrest_date'])
cleaned.head()
```

```{python}
#| echo: false

# percent missing; descriptive statistics; categorical frequency tables

print(cleaned.isna().sum() / len(cleaned))
print(cleaned.describe())

print(cleaned["arrest_boro"].value_counts(dropna = False))
print(cleaned["arrest_precinct"].value_counts(dropna = False))
print(cleaned["perp_sex"].value_counts(dropna = False))
print(cleaned["age_group"].value_counts(dropna = False))
print(cleaned["perp_race"].value_counts(dropna = False))
print(cleaned["law_cat_cd"].value_counts(dropna = False))
print(cleaned["law_code"].value_counts(dropna = False))
print(cleaned["ofns_desc"].value_counts(dropna = False))
```


The data is already pretty clean. We will make a few adjustments.

```{python}
#| echo: false
import numpy as np 

# clean codes so we only have misdeamenor, violation, and felony
cleaned = cleaned.replace(['9', 'I', None], np.nan)
print(cleaned["law_cat_cd"].value_counts(dropna = False))
```

```{python}
#| echo: false

# imports 
from uszipcode import SearchEngine
import numpy as np
from typing import Union, List


cleaned['latitude'] = cleaned['latitude'].astype(float)
cleaned['longitude'] = cleaned['longitude'].astype(float)

sr = SearchEngine()
zipcodes = [int(sr.by_coordinates(lat, lng, radius=5)[0].zipcode) for lat, lng in zip(cleaned['latitude'],cleaned['longitude'])]

```

```{python}
import pandas as pd
zipcodes = pd.Series(zipcodes)
# add the zipcodes as a new column to the dataframe
cleaned['arrest_zipcode'] = zipcodes.values

# printing to show that it works
cleaned.head()
```

## Exploratory Analysis and Graphing

```{python}
# graph the arrests

# plot by the race of the arrested

cleaned.explore(column = "perp_race", legend = True)
cleaned.explore(column = "perp_sex", legend = True)
cleaned.explore(column = "age_group", legend = True)
```


## Graphing by Precincts

```{python}
precincts = gpd.read_file("data/nyc_police_precincts.geojson")
precincts = precincts.rename(columns={"precinct":"arrest_precinct"})

# precinct by age
age_counts = cleaned.groupby(['arrest_precinct', 'age_group']).size().reset_index(name='count')
idx = age_counts.groupby('arrest_precinct')['count'].idxmax()
max_counts = age_counts.loc[idx]
max_counts = max_counts.drop(columns='count')
precincts = precincts.merge(max_counts, on='arrest_precinct')
precincts.plot(column="age_group", legend = True)


# precincts by race
race_counts = cleaned.groupby(['arrest_precinct', 'perp_race']).size().reset_index(name='count')
idx = race_counts.groupby('arrest_precinct')['count'].idxmax()
max_race_counts = race_counts.loc[idx]
max_race_counts = max_race_counts.drop(columns='count')
precincts = precincts.merge(max_race_counts, on='arrest_precinct')
precincts.plot(column="perp_race", legend=True)


# precincts by sex
sex_counts = cleaned.groupby(['arrest_precinct', 'perp_sex']).size().reset_index(name='count')
idx = sex_counts.groupby('arrest_precinct')['count'].idxmax()
max_sex_counts = sex_counts.loc[idx]
max_sex_counts = max_sex_counts.drop(columns='count')
precincts = precincts.merge(max_sex_counts, on='arrest_precinct')
precincts.plot(column="perp_sex", legend=True)

# precincts by description
desc_counts = cleaned.groupby(['arrest_precinct', 'ofns_desc']).size().reset_index(name='count')
idx = desc_counts.groupby('arrest_precinct')['count'].idxmax()
max_desc_counts = desc_counts.loc[idx]
max_desc_counts = max_desc_counts.drop(columns='count')
precincts = precincts.merge(max_desc_counts, on='arrest_precinct')
precincts.explore(column='ofns_desc', legend = True)
```

## Hypothesis Testing
We will test whether the distribution is the same across the precincts. We will perform a Chi-squared test where our null hypothesis is that the distribution of perpertrator race for each precinct
is the same, and the null hypothesis is that the distribution of races are not the same across 
the precincts. At a chosen significance level of 0.05, we can conclude that the distributions of 
durations are significantly different across the different boroughs, since our 
p-value is < 0.00001. 

This is an interesting observation. It is likely that the different precincts have different demographic distributions. However, with further analysis, we may be able to determine if certain police precincts commit racial injustices. This could be determined by examining the distributions of races in the neighborhood of the precinct and comparing if the arrests are proportional to the population.

```{python}
import pandas as pd
from scipy.stats import chi2_contingency

# create a contingency table of perpetrator race and precinct
cont_table = pd.crosstab(cleaned['perp_race'], cleaned['arrest_precinct'], margins=True)

# perform the chi-squared test of independence
chi2, pval, dof, expected = chi2_contingency(cont_table)

# print the results
print('Chi-squared statistic:', chi2)
print('P-value:', pval)
print('Degrees of freedom:', dof)
print('Expected frequencies:', expected)
```

We do the same for age and sex, and we find, again, that the distributions are not the same across the precincts.

```{python}
import pandas as pd
from scipy.stats import chi2_contingency

# create a contingency table of perpetrator race and precinct
cont_table = pd.crosstab(cleaned['perp_sex'], cleaned['arrest_precinct'], margins=True)

# perform the chi-squared test of independence
chi2, pval, dof, expected = chi2_contingency(cont_table)

# print the results
print('Chi-squared statistic:', chi2)
print('P-value:', pval)
print('Degrees of freedom:', dof)
print('Expected frequencies:', expected)
```


```{python}
import pandas as pd
from scipy.stats import chi2_contingency

# create a contingency table of perpetrator race and precinct
cont_table = pd.crosstab(cleaned['age_group'], cleaned['arrest_precinct'], margins=True)

# perform the chi-squared test of independence
chi2, pval, dof, expected = chi2_contingency(cont_table)

# print the results
print('Chi-squared statistic:', chi2)
print('P-value:', pval)
print('Degrees of freedom:', dof)
print('Expected frequencies:', expected)
```
## Modeling

# Conclusions